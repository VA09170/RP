{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the captions from json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os, os.path\n",
    "import pickle\n",
    "\n",
    "train_val = json.load(open('videodatainfo_2017.json', 'r'))\n",
    "\n",
    "\n",
    "# combine all images and annotations together\n",
    "sentences = train_val['sentences']\n",
    "\n",
    "# for efficiency lets group annotations by video\n",
    "itoa = {}\n",
    "for s in sentences:\n",
    "    videoid_buf = s['video_id']\n",
    "    videoid = int(videoid_buf[5:])\n",
    "    if not videoid in itoa: itoa[videoid] = []\n",
    "    itoa[videoid].append(s)\n",
    "    \n",
    "output = open('./DATA/word_features/captions.pkl', 'wb')\n",
    "pickle.dump(itoa, output)\n",
    "output.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxilary functions to handle captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"Functions to do the following:\n",
    "            * Create vocabulary\n",
    "            * Create dictionary mapping from word to word_id\n",
    "            * Map words in captions to word_ids\"\"\"\n",
    "\n",
    "def build_vocab(word_count_thresh):\n",
    "    \"\"\"Function to create vocabulary based on word count threshold.\n",
    "        Input:\n",
    "                word_count_thresh: Threshold to choose words to include to the vocabulary\n",
    "        Output:\n",
    "                vocabulary: Set of words in the vocabulary\"\"\"\n",
    "    \n",
    "    pkl_file = open('./DATA/word_features/captions.pkl', 'rb')\n",
    "    sentences = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "\n",
    "    unk_required = False\n",
    "    all_captions = []\n",
    "    word_counts = {}\n",
    "    for vid in sentences.keys():\n",
    "        for cid in range(0,20):\n",
    "            caption = sentences[vid][cid]['caption']\n",
    "            caption = '<BOS> ' + caption + ' <EOS>'\n",
    "            all_captions.append(caption)\n",
    "            for word in caption.split(' '):\n",
    "                if word in word_counts.keys():\n",
    "                    word_counts[word] += 1\n",
    "                else:\n",
    "                    word_counts[word] = 1\n",
    "    for word in word_counts.keys():\n",
    "        if word_counts[word] < word_count_thresh:\n",
    "            word_counts.pop(word)\n",
    "            unk_required = True\n",
    "    return word_counts,unk_required\n",
    "\n",
    "def word_to_word_ids(word_counts,unk_required, vocab_size):\n",
    "    \"\"\"Function to map individual words to their id's.\n",
    "        Input:\n",
    "                word_counts: Dictionary with words mapped to their counts\n",
    "        Output:\n",
    "                word_to_id: Dictionary with words mapped to their id's. \n",
    "    \"\"\"\n",
    "\n",
    "    count = 0\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    # Taking the most frequent vocab_size words\n",
    "    words = [word for word in word_counts.keys()]\n",
    "    values = [word_counts[word] for word in words]\n",
    "    sorted_indices = np.argsort(values)\n",
    "    words = np.array(words)\n",
    "    most_freq_words = words[sorted_indices[::-1][0:vocab_size]]\n",
    "    \n",
    "    id_to_word = [most_freq_words[i] for i in range(most_freq_words.shape[0])] \n",
    "    \n",
    "    #word2idx\n",
    "    word_to_id = {}\n",
    "    for i in range(len(id_to_word)):\n",
    "        word_to_id[id_to_word[i]] = i\n",
    "    \n",
    "    print(word_to_id['<EOS>'])\n",
    "    index = word_to_id['<EOS>']\n",
    "    word = id_to_word[0]\n",
    "    print(index,word)\n",
    "    \n",
    "    word_to_id['<EOS>'] = 0\n",
    "    id_to_word[0] = '<EOS>'\n",
    "    word_to_id[word] = index\n",
    "    id_to_word[index] = word\n",
    "    \n",
    "    return word_to_id,id_to_word\n",
    "\n",
    "def convert_caption(caption,word_to_id,max_caption_length):\n",
    "    \"\"\"Function to map each word in a caption to it's respective id and to retrieve caption masks\n",
    "        Input:\n",
    "                caption: Caption to convert to word_to_word_ids\n",
    "                word_to_id: Dictionary mapping words to their respective id's\n",
    "                max_caption_length: Maximum number of words allowed in a caption\n",
    "        Output:\n",
    "                caps: Captions with words mapped to word id's\n",
    "                cap_masks: Caption masks with 1's at positions of words and 0's at pad locations\"\"\"\n",
    "    caps,cap_masks = [],[]\n",
    "    if type(caption) == 'str':\n",
    "        caption = [caption] # if single caption, make it a list of captions of length one\n",
    "    for cap in caption:\n",
    "        cap = '<BOS> '+cap+' <EOS>'\n",
    "        nWords = cap.count(' ') + 1\n",
    "        if nWords >= max_caption_length:\n",
    "            carr = cap.split(' ')\n",
    "            carr = carr[0:(max_caption_length-2)]\n",
    "            cap  = ' '.join(carr)\n",
    "            cap  = cap + ' <EOS>'\n",
    "            nWords = cap.count(' ')+1\n",
    "        cap = cap + ' <EOS>'*(max_caption_length-nWords)\n",
    "        cap_masks.append([1.0]*nWords + [0.0]*(max_caption_length-nWords))\n",
    "        curr_cap = []\n",
    "        for word in cap.split(' '):\n",
    "            #print(word)\n",
    "            if word in word_to_id.keys():\n",
    "                curr_cap.append(word_to_id[word]) # word is present in chosen vocabulary\n",
    "            else:\n",
    "                curr_cap.append(word_to_id['<UNK>']) # word not present in chosen vocabulary\n",
    "        caps.append(curr_cap)\n",
    "        #print('Caption_Length:',len(caps[0]))\n",
    "    return np.array(caps),np.array(cap_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test  Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the list of the files we have extracted features\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "video_list = os.listdir('./DATA/features')\n",
    "videos = []\n",
    "for item in video_list:\n",
    "    videos.append(item.split('-')[0])\n",
    "\n",
    "video_train, video_test = train_test_split(videos, test_size=0.1, random_state=42)\n",
    "video_train, video_val = train_test_split(video_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Videos - 5890\n",
      "Testing Videos - 728\n",
      "Validation Videos - 655\n"
     ]
    }
   ],
   "source": [
    "print('Training Videos -', len(video_train))\n",
    "print('Testing Videos -', len(video_test))\n",
    "print('Validation Videos -', len(video_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxillary functions to handle model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2 a\n",
      "5890 files processed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import cv2\n",
    "import imageio\n",
    "import pickle\n",
    "np.random.seed(0)\n",
    "#Global initializations\n",
    "n_lstm_steps = 30\n",
    "DATA_DIR = './DATA/'\n",
    "VIDEO_DIR = DATA_DIR + 'features/'\n",
    "YOUTUBE_CLIPS_DIR = DATA_DIR + 'videos/'\n",
    "TEXT_DIR = DATA_DIR+'word_features/'\n",
    "pkl_file = open('./DATA/word_features/captions.pkl', 'rb')\n",
    "sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "word_counts,unk_required = build_vocab(0)\n",
    "word2id,id2word = word_to_word_ids(word_counts,unk_required, len(word_counts.keys()))\n",
    "video_files = video_train\n",
    "val_files = video_val\n",
    "\n",
    "print (\"{0} files processed\".format(len(video_files)))\n",
    "\n",
    "def get_bias_vector():\n",
    "    \"\"\"Function to return the initialization for the bias vector\n",
    "       for mapping from hidden_dim to vocab_size.\n",
    "       Borrowed from neuraltalk by Andrej Karpathy\"\"\"\n",
    "    bias_init_vector = np.array([1.0*word_counts[id2word[i]] for i in range(len(id2word))])\n",
    "    bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector)\n",
    "    return bias_init_vector\n",
    "\n",
    "def fetch_data_batch(batch_size):\n",
    "    \"\"\"Function to fetch a batch of video features, captions and caption masks\n",
    "        Input:\n",
    "                batch_size: Size of batch to load\n",
    "        Output:\n",
    "                curr_vids: Features of the randomly selected batch of video_files\n",
    "                curr_caps: Ground truth (padded) captions for the selected videos\n",
    "                curr_masks: Mask for the pad locations in curr_caps\"\"\"\n",
    "    curr_batch_vids = np.random.choice(video_files,batch_size)\n",
    "    curr_vids = np.array([np.load(VIDEO_DIR + vid+'-30-features' + '.npy') for vid in curr_batch_vids])\n",
    "    captions = [np.random.choice(sentences[int(vid[5:])],1)[0]['caption'] for vid in curr_batch_vids]\n",
    "    curr_caps,curr_masks = convert_caption(captions,word2id,n_lstm_steps)\n",
    "    return curr_vids,curr_caps,curr_masks\n",
    "\n",
    "def fetch_data_batch_val(batch_size):\n",
    "    \"\"\"Function to fetch a batch of video features from the validation set and its captions.\n",
    "        Input:\n",
    "                batch_size: Size of batch to load\n",
    "        Output:\n",
    "                curr_vids: Features of the randomly selected batch of video_files\n",
    "                curr_caps: Ground truth (padded) captions for the selected videos\"\"\"\n",
    "\n",
    "    curr_batch_vids = np.random.choice(val_files,batch_size)\n",
    "    curr_vids = np.array([np.load(VIDEO_DIR +vid+'-30-features' + '.npy') for vid in curr_batch_vids])\n",
    "    captions = [np.random.choice(sentences[int(vid[5:])],1)[0]['caption'] for vid in curr_batch_vids]\n",
    "    curr_caps,curr_masks = convert_caption(captions,word2id,n_lstm_steps)\n",
    "    return curr_vids,curr_caps,curr_masks, curr_batch_vids\n",
    "\n",
    "\n",
    "def print_in_english(caption_idx):\n",
    "    \"\"\"Function to take a list of captions with words mapped to ids and\n",
    "        print the captions after mapping word indices back to words.\"\"\"\n",
    "    captions_english = [[id2word[word] for word in caption] for caption in caption_idx]\n",
    "    for i,caption in enumerate(captions_english):\n",
    "        if '<EOS>' in caption:\n",
    "            caption = caption[0:caption.index('<EOS>')]\n",
    "        print (str(i+1) + ' ' + ' '.join(caption))\n",
    "        print ('..................................................')\n",
    "\n",
    "def playVideo(video_urls):\n",
    "    video = imageio.get_reader(YOUTUBE_CLIPS_DIR + video_urls[0] + '.mp4','ffmpeg')\n",
    "    for frame in video:\n",
    "        fr = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('frame',fr)\n",
    "        if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    }
   ],
   "source": [
    "print(len(word2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a woman showing how to make cookies'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_val = 'video3707'\n",
    "np.random.choice(sentences[int(tmp_val[5:])],1)[0]['caption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata = np.load(VIDEO_DIR+'video0-30-features.npy')\n",
    "tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29325"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<EOS> 1\n"
     ]
    }
   ],
   "source": [
    "print(id2word[0], word2id['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#GLOBAL VARIABLE INITIALIZATIONS TO BUILD MODEL\n",
    "n_steps = 30\n",
    "hidden_dim = 500\n",
    "frame_dim = 2048\n",
    "batch_size = 1\n",
    "vocab_size = len(word2id)\n",
    "bias_init_vector = get_bias_vector()\n",
    "n_steps_vocab = 30\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"This function creates weight matrices that transform:\n",
    "            * frames to caption dimension\n",
    "            * hidden state to vocabulary dimension\n",
    "            * creates word embedding matrix \"\"\"\n",
    "\n",
    "    print (\"Network config: \\nN_Steps: {}\\nHidden_dim:{}\\nFrame_dim:{}\\nBatch_size:{}\\nVocab_size:{}\\n\".format(n_steps,\n",
    "                                                                                                    hidden_dim,\n",
    "                                                                                                    frame_dim,\n",
    "                                                                                                    batch_size,\n",
    "                                                                                                    vocab_size))\n",
    "\n",
    "    #Create placeholders for holding a batch of videos, captions and caption masks\n",
    "    video = tf.placeholder(tf.float32,shape=[batch_size,n_steps,frame_dim],name='Input_Video')\n",
    "    caption = tf.placeholder(tf.int32,shape=[batch_size,n_steps_vocab],name='GT_Caption')\n",
    "    caption_mask = tf.placeholder(tf.float32,shape=[batch_size,n_steps_vocab],name='Caption_Mask')\n",
    "    dropout_prob = tf.placeholder(tf.float32,name='Dropout_Keep_Probability')\n",
    "\n",
    "    with tf.variable_scope('Im2Cap') as scope:\n",
    "        W_im2cap = tf.get_variable(name='W_im2cap',shape=[frame_dim,\n",
    "                                                    hidden_dim],\n",
    "                                                    initializer=tf.random_uniform_initializer(minval=-0.08,maxval=0.08))\n",
    "        b_im2cap = tf.get_variable(name='b_im2cap',shape=[hidden_dim],\n",
    "                                                    initializer=tf.constant_initializer(0.0))\n",
    "    with tf.variable_scope('Hid2Vocab') as scope:\n",
    "        W_H2vocab = tf.get_variable(name='W_H2vocab',shape=[hidden_dim,vocab_size],\n",
    "                                                         initializer=tf.random_uniform_initializer(minval=-0.08,maxval=0.08))\n",
    "        b_H2vocab = tf.Variable(name='b_H2vocab',initial_value=bias_init_vector.astype(np.float32))\n",
    "\n",
    "    with tf.variable_scope('Word_Vectors') as scope:\n",
    "        word_emb = tf.get_variable(name='Word_embedding',shape=[vocab_size,hidden_dim],\n",
    "                                                                initializer=tf.random_uniform_initializer(minval=-0.08,maxval=0.08))\n",
    "    print (\"Created weights\")\n",
    "\n",
    "    #Build two LSTMs, one for processing the video and another for generating the caption\n",
    "    with tf.variable_scope('LSTM_Video',reuse=None) as scope:\n",
    "        lstm_vid = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "        lstm_vid = tf.nn.rnn_cell.DropoutWrapper(lstm_vid,output_keep_prob=dropout_prob)\n",
    "    with tf.variable_scope('LSTM_Caption',reuse=None) as scope:\n",
    "        lstm_cap = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "        lstm_cap = tf.nn.rnn_cell.DropoutWrapper(lstm_cap,output_keep_prob=dropout_prob)\n",
    "\n",
    "    #Prepare input for lstm_video\n",
    "    video_rshp = tf.reshape(video,[-1,frame_dim])\n",
    "    video_rshp = tf.nn.dropout(video_rshp,keep_prob=dropout_prob)\n",
    "    video_emb = tf.nn.xw_plus_b(video_rshp,W_im2cap,b_im2cap)\n",
    "    video_emb = tf.reshape(video_emb,[batch_size,n_steps,hidden_dim])\n",
    "    padding = tf.zeros([batch_size,n_steps-1,hidden_dim])\n",
    "    video_input = tf.concat([video_emb,padding],1)\n",
    "    #video_input=video_emb\n",
    "    print (\"Video_input: {}\".format(video_input.get_shape()))\n",
    "    #Run lstm_vid for 2*n_steps-1 timesteps\n",
    "    with tf.variable_scope('LSTM_Video') as scope:\n",
    "        out_vid,state_vid = tf.nn.dynamic_rnn(lstm_vid,video_input,dtype=tf.float32)\n",
    "    print (\"Video_output: {}\".format(out_vid.get_shape()))\n",
    "\n",
    "    #Prepare input for lstm_cap\n",
    "    padding = tf.zeros([batch_size,n_steps_vocab,hidden_dim])\n",
    "    caption_vectors = tf.nn.embedding_lookup(word_emb,caption[:,0:n_steps_vocab-1])\n",
    "    caption_vectors = tf.nn.dropout(caption_vectors,keep_prob=dropout_prob)\n",
    "    caption_2n = tf.concat([padding,caption_vectors],1)\n",
    "    #caption_2n = caption_vectors\n",
    "    caption_input = tf.concat([caption_2n,out_vid],2)\n",
    "    print (\"Caption_input: {}\".format(caption_input.get_shape()))\n",
    "    #Run lstm_cap for 2*n_steps-1 timesteps\n",
    "    with tf.variable_scope('LSTM_Caption') as scope:\n",
    "        out_cap,state_cap = tf.nn.dynamic_rnn(lstm_cap,caption_input,dtype=tf.float32)\n",
    "    print (\"Caption_output: {}\".format(out_cap.get_shape()))\n",
    "\n",
    "    #Compute masked loss\n",
    "    output_captions = out_cap[:,n_steps_vocab:,:]\n",
    "    output_logits = tf.reshape(output_captions,[-1,hidden_dim])\n",
    "    output_logits = tf.nn.dropout(output_logits,keep_prob=dropout_prob)\n",
    "    output_logits = tf.nn.xw_plus_b(output_logits,W_H2vocab,b_H2vocab)\n",
    "    output_labels = tf.reshape(caption[:,1:],[-1])\n",
    "    caption_mask_out = tf.reshape(caption_mask[:,1:],[-1])\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output_logits,labels=output_labels)\n",
    "    masked_loss = loss*caption_mask_out\n",
    "    loss = tf.reduce_sum(masked_loss)/tf.reduce_sum(caption_mask_out)\n",
    "    return video,caption,caption_mask,output_logits,loss,dropout_prob\n",
    "\n",
    "db1 = None\n",
    "db2 = None\n",
    "db3 = None\n",
    "def train():\n",
    "    global db1,db2,db3\n",
    "    with tf.Graph().as_default():\n",
    "        learning_rate = 0.0001\n",
    "        video,caption,caption_mask,output_logits,loss,dropout_prob = build_model()\n",
    "        optim = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "        nEpoch = 300\n",
    "        nIter = int(nEpoch*6000/batch_size)\n",
    "        \n",
    "        ckpt_file = './ckpt_v4/model_58000.ckpt.meta'\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            if ckpt_file:\n",
    "                saver_ = tf.train.import_meta_graph(ckpt_file)\n",
    "                saver_.restore(sess,'./ckpt_v4/model_58000.ckpt')\n",
    "                print (\"Restored model\")\n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "            for i in range(nIter):\n",
    "                #print(i)\n",
    "                vids,caps,caps_mask = fetch_data_batch(batch_size=batch_size)\n",
    "                db1,db2,db3 = vids, caps, caps_mask\n",
    "                #print(type(vids),type(caps), type(caps_mask))\n",
    "                #print(vids,caps, caps_mask)\n",
    "                _,curr_loss,o_l = sess.run([optim,loss,output_logits],feed_dict={video:vids,\n",
    "                                                                            caption:caps,\n",
    "                                                                            caption_mask:caps_mask,\n",
    "                                                                            dropout_prob:0.5})\n",
    "\n",
    "                if i%1000 == 0:\n",
    "                    print (\"\\nIteration {} \\n\".format(i))\n",
    "                    out_logits = o_l.reshape([batch_size,n_steps_vocab-1,vocab_size])\n",
    "                    output_captions = np.argmax(out_logits,2)\n",
    "                    #print_in_english(output_captions[0:4])\n",
    "                    #print (\"GT Captions\")\n",
    "                    #print_in_english(caps[0:4])\n",
    "                    print (\"Current train loss: {} \".format(curr_loss))\n",
    "                    vids,caps,caps_mask,_ = fetch_data_batch_val(batch_size=batch_size)\n",
    "                    db1,db2,db3 = vids,caps,caps_mask\n",
    "                    curr_loss,o_l = sess.run([loss,output_logits],feed_dict={video:vids,\n",
    "                                                                            caption:caps,\n",
    "                                                                            caption_mask:caps_mask,\n",
    "                                                                            dropout_prob:1.0})\n",
    "                    out_logits = o_l.reshape([batch_size,n_steps_vocab-1,vocab_size])\n",
    "                    output_captions = np.argmax(out_logits,2)\n",
    "                    print_in_english(output_captions[0:2])\n",
    "                    print (\"GT Captions\")\n",
    "                    print_in_english(caps[0:2])\n",
    "                    print (\"Current validation loss: {} \".format(curr_loss))\n",
    "\n",
    "                if i%2000 == 0:\n",
    "                    saver.save(sess,'./ckpt_v5/model_'+str(i)+'.ckpt')\n",
    "                    print ('Saved {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Begins !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network config: \n",
      "N_Steps: 30\n",
      "Hidden_dim:500\n",
      "Frame_dim:2048\n",
      "Batch_size:30\n",
      "Vocab_size:29325\n",
      "\n",
      "Created weights\n",
      "Video_input: (30, 59, 500)\n",
      "Video_output: (30, 59, 500)\n",
      "Caption_input: (30, 59, 1000)\n",
      "Caption_output: (30, 59, 500)\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_v4/model_58000.ckpt\n",
      "Restored model\n",
      "\n",
      "Iteration 0 \n",
      "\n",
      "Current train loss: 5.710939407348633 \n",
      "1 man are <BOS>\n",
      "..................................................\n",
      "2 man men are <BOS> <BOS> on on <BOS>\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> men drawing guns and then football player playing\n",
      "..................................................\n",
      "2 <BOS> two men driving a ferrari\n",
      "..................................................\n",
      "Current validation loss: 6.091744422912598 \n",
      "Saved 0\n",
      "\n",
      "Iteration 1000 \n",
      "\n",
      "Current train loss: 3.989447593688965 \n",
      "1 a are a\n",
      "..................................................\n",
      "2 a are on a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> montage of baseball players celebrating to intense music\n",
      "..................................................\n",
      "2 <BOS> people working on engines\n",
      "..................................................\n",
      "Current validation loss: 3.8030765056610107 \n",
      "\n",
      "Iteration 2000 \n",
      "\n",
      "Current train loss: 4.344245910644531 \n",
      "1 a man is a guitar\n",
      "..................................................\n",
      "2 a old man is about the\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man playing a guitar\n",
      "..................................................\n",
      "2 <BOS> an old man talks about cats\n",
      "..................................................\n",
      "Current validation loss: 4.4142632484436035 \n",
      "Saved 2000\n",
      "\n",
      "Iteration 3000 \n",
      "\n",
      "Current train loss: 3.8703577518463135 \n",
      "1 two men are wrestling\n",
      "..................................................\n",
      "2 a man is with game\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> two guys are wrestling in a competition\n",
      "..................................................\n",
      "2 <BOS> a boy playing the piano\n",
      "..................................................\n",
      "Current validation loss: 4.140491962432861 \n",
      "\n",
      "Iteration 4000 \n",
      "\n",
      "Current train loss: 3.676469087600708 \n",
      "1 a woman is is and a\n",
      "..................................................\n",
      "2 a man is a cartoon\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a person slices potatoes into smaller pieces\n",
      "..................................................\n",
      "2 <BOS> a man in the rain looking at a rock\n",
      "..................................................\n",
      "Current validation loss: 3.797583818435669 \n",
      "Saved 4000\n",
      "\n",
      "Iteration 5000 \n",
      "\n",
      "Current train loss: 4.081212997436523 \n",
      "1 a man is a news show\n",
      "..................................................\n",
      "2 a is a man is shown about the people\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man read the tv flash news and market rates\n",
      "..................................................\n",
      "2 <BOS> hero of the film is talking to some girls very seriously and the girl listens carefully\n",
      "..................................................\n",
      "Current validation loss: 4.362054824829102 \n",
      "\n",
      "Iteration 6000 \n",
      "\n",
      "Current train loss: 4.080102443695068 \n",
      "1 a person is cooking food cooking\n",
      "..................................................\n",
      "2 a boy are with house\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a person is peeling and mashing cooked poatoes\n",
      "..................................................\n",
      "2 <BOS> the kids play the theft and police\n",
      "..................................................\n",
      "Current validation loss: 3.6474521160125732 \n",
      "Saved 6000\n",
      "\n",
      "Iteration 7000 \n",
      "\n",
      "Current train loss: 4.0086588859558105 \n",
      "1 a women are are at a men men\n",
      "..................................................\n",
      "2 a man is is being a and and and and\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> two bored women look at two other women who are excitedly speaking\n",
      "..................................................\n",
      "2 <BOS> a quad chopter is delivering drinks\n",
      "..................................................\n",
      "Current validation loss: 4.521246910095215 \n",
      "\n",
      "Iteration 8000 \n",
      "\n",
      "Current train loss: 4.09481143951416 \n",
      "1 a are on a chair room\n",
      "..................................................\n",
      "2 two men are are wrestling\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> men sitting in a locker room talking\n",
      "..................................................\n",
      "2 <BOS> two man s are fighting with each other on the ground\n",
      "..................................................\n",
      "Current validation loss: 4.40539026260376 \n",
      "Saved 8000\n",
      "\n",
      "Iteration 9000 \n",
      "\n",
      "Current train loss: 3.190986394882202 \n",
      "1 a talking about news of\n",
      "..................................................\n",
      "2 a man is talking about\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> man discussing the swastica s on each man\n",
      "..................................................\n",
      "2 <BOS> a man is talking\n",
      "..................................................\n",
      "Current validation loss: 4.049018859863281 \n",
      "\n",
      "Iteration 10000 \n",
      "\n",
      "Current train loss: 3.836989164352417 \n",
      "1 a man man is is is is a on a animated\n",
      "..................................................\n",
      "2 a man is a is is a and\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a first person shooter game that takes place in an outdoor area\n",
      "..................................................\n",
      "2 <BOS> a sticker of biker man\n",
      "..................................................\n",
      "Current validation loss: 3.7681522369384766 \n",
      "Saved 10000\n",
      "\n",
      "Iteration 11000 \n",
      "\n",
      "Current train loss: 3.4665136337280273 \n",
      "1 a man is a blue of shirt is walking down the road road\n",
      "..................................................\n",
      "2 a girl playing are playing to playing is playing\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a woman in a lime green shirt is running down a dirt road through the forest\n",
      "..................................................\n",
      "2 <BOS> three barbie dolls are talking while one is examining the foot of one of the dolls to see if it is hurt\n",
      "..................................................\n",
      "Current validation loss: 3.5693869590759277 \n",
      "\n",
      "Iteration 12000 \n",
      "\n",
      "Current train loss: 3.8586039543151855 \n",
      "1 a cartoon animals a animals\n",
      "..................................................\n",
      "2 a man of on song\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> animated cartoon with sick monkey\n",
      "..................................................\n",
      "2 <BOS> a group performing a show\n",
      "..................................................\n",
      "Current validation loss: 4.297967433929443 \n",
      "Saved 12000\n",
      "\n",
      "Iteration 13000 \n",
      "\n",
      "Current train loss: 3.591733694076538 \n",
      "1 a man man is being on a kitchen\n",
      "..................................................\n",
      "2 a girl girl is a talking a hair\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a shirtless teenager is working in the kitchen and commenting upon his actions\n",
      "..................................................\n",
      "2 <BOS> a young woman washing and combing her hair\n",
      "..................................................\n",
      "Current validation loss: 4.377688884735107 \n",
      "\n",
      "Iteration 14000 \n",
      "\n",
      "Current train loss: 3.4024927616119385 \n",
      "1 a man is being played\n",
      "..................................................\n",
      "2 a small is walking around the stairs and\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a game is been played by the person in his computer\n",
      "..................................................\n",
      "2 <BOS> a person is walking down some steep stairs with heavy plant growth to the sides\n",
      "..................................................\n",
      "Current validation loss: 3.9335079193115234 \n",
      "Saved 14000\n",
      "\n",
      "Iteration 15000 \n",
      "\n",
      "Current train loss: 3.353208303451538 \n",
      "1 a is how to use a\n",
      "..................................................\n",
      "2 a man is showing on a and on\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> woman showing how to keep things in the new product\n",
      "..................................................\n",
      "2 <BOS> a person is working with yellow twine wrapped around their hand\n",
      "..................................................\n",
      "Current validation loss: 3.9493484497070312 \n",
      "\n",
      "Iteration 16000 \n",
      "\n",
      "Current train loss: 3.4370555877685547 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 a talking talking and playing\n",
      "..................................................\n",
      "2 a animated cartoon is at\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> women are singing and dancing\n",
      "..................................................\n",
      "2 <BOS> an old man looks around suspiciously\n",
      "..................................................\n",
      "Current validation loss: 3.7483720779418945 \n",
      "Saved 16000\n",
      "\n",
      "Iteration 17000 \n",
      "\n",
      "Current train loss: 3.6277105808258057 \n",
      "1 a man is around a video\n",
      "..................................................\n",
      "2 a are in and costumes\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man running in the wilderness\n",
      "..................................................\n",
      "2 <BOS> children dressed up in costumes\n",
      "..................................................\n",
      "Current validation loss: 3.73954176902771 \n",
      "\n",
      "Iteration 18000 \n",
      "\n",
      "Current train loss: 3.2740445137023926 \n",
      "1 a animated man is in a a video\n",
      "..................................................\n",
      "2 a man is talking about a audience man\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> an animated machine gun firing in a game\n",
      "..................................................\n",
      "2 <BOS> a girl is talking to an old woman\n",
      "..................................................\n",
      "Current validation loss: 4.621544361114502 \n",
      "Saved 18000\n",
      "\n",
      "Iteration 19000 \n",
      "\n",
      "Current train loss: 3.7405831813812256 \n",
      "1 a group is being\n",
      "..................................................\n",
      "2 a man is talking about a he and shown\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a protest is shown talking about where is my midwife\n",
      "..................................................\n",
      "2 <BOS> a woman is talking about why chairs are made\n",
      "..................................................\n",
      "Current validation loss: 3.867302417755127 \n",
      "\n",
      "Iteration 20000 \n",
      "\n",
      "Current train loss: 3.151510000228882 \n",
      "1 a is driving a car and the road\n",
      "..................................................\n",
      "2 a man is a video game\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> someone is driving a car on a road\n",
      "..................................................\n",
      "2 <BOS> a man narrates a video game\n",
      "..................................................\n",
      "Current validation loss: 4.10455846786499 \n",
      "Saved 20000\n",
      "\n",
      "Iteration 21000 \n",
      "\n",
      "Current train loss: 3.5305304527282715 \n",
      "1 a a white and dog is the and the the dog is the the the\n",
      "..................................................\n",
      "2 two are two men wrestling a wrestling match\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> in a studio the guest drinks milk and then the anchor also drinks\n",
      "..................................................\n",
      "2 <BOS> there are two guys in a wrestling match\n",
      "..................................................\n",
      "Current validation loss: 3.75028395652771 \n",
      "\n",
      "Iteration 22000 \n",
      "\n",
      "Current train loss: 3.4528427124023438 \n",
      "1 a man of men men is are to\n",
      "..................................................\n",
      "2 a people are a kitchen\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a list of famous movie quotes\n",
      "..................................................\n",
      "2 <BOS> two mens in the kitchen putting a huge hambuger patty weighing 5lbs on the grill\n",
      "..................................................\n",
      "Current validation loss: 4.172888278961182 \n",
      "Saved 22000\n",
      "\n",
      "Iteration 23000 \n",
      "\n",
      "Current train loss: 3.9369425773620605 \n",
      "1 a man is talking a interview with the\n",
      "..................................................\n",
      "2 a people are in in table\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man is having an interview about cures for a disease\n",
      "..................................................\n",
      "2 <BOS> three people stand around a plate of decorated cupcakes on a kitchen island\n",
      "..................................................\n",
      "Current validation loss: 3.5595343112945557 \n",
      "\n",
      "Iteration 24000 \n",
      "\n",
      "Current train loss: 3.5894854068756104 \n",
      "1 a man is a\n",
      "..................................................\n",
      "2 a are driving at a car\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a person shoots basketball in to the ring\n",
      "..................................................\n",
      "2 <BOS> people are looking at a porsche\n",
      "..................................................\n",
      "Current validation loss: 3.4224770069122314 \n",
      "Saved 24000\n",
      "\n",
      "Iteration 25000 \n",
      "\n",
      "Current train loss: 3.950505495071411 \n",
      "1 a man man is working to work a a machine\n",
      "..................................................\n",
      "2 a man is a car\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a young man is trying to take apart a motorcycle\n",
      "..................................................\n",
      "2 <BOS> a man drives a car around a track\n",
      "..................................................\n",
      "Current validation loss: 3.142472982406616 \n",
      "\n",
      "Iteration 26000 \n",
      "\n",
      "Current train loss: 3.4615225791931152 \n",
      "1 a is a man is about a of a crowd\n",
      "..................................................\n",
      "2 a is some to make some food in a oven bowl\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> there is a man talking in front of a drawings\n",
      "..................................................\n",
      "2 <BOS> person showing how to put sweet potatoes in an ice tray\n",
      "..................................................\n",
      "Current validation loss: 3.5124804973602295 \n",
      "Saved 26000\n",
      "\n",
      "Iteration 27000 \n",
      "\n",
      "Current train loss: 3.377565383911133 \n",
      "1 a are a car on on\n",
      "..................................................\n",
      "2 a man of a video game\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> people riding a motorcycle\n",
      "..................................................\n",
      "2 <BOS> a part of a baseball competition\n",
      "..................................................\n",
      "Current validation loss: 3.8592236042022705 \n",
      "\n",
      "Iteration 28000 \n",
      "\n",
      "Current train loss: 3.4858477115631104 \n",
      "1 a man of people men are on playing a\n",
      "..................................................\n",
      "2 a men are a in a field field\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a group of young men joke and play outdoor games and sports\n",
      "..................................................\n",
      "2 <BOS> several men play around on a baseball field\n",
      "..................................................\n",
      "Current validation loss: 4.195500373840332 \n",
      "Saved 28000\n",
      "\n",
      "Iteration 29000 \n",
      "\n",
      "Current train loss: 3.5903961658477783 \n",
      "1 a is a game\n",
      "..................................................\n",
      "2 a man scene from in  speaking   displaying  displaying man   speaking man standing  on screen\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> it was video game  where the car is travelling very fast and covering the distance\n",
      "..................................................\n",
      "2 <BOS> a movie scene boy stading girl seeing smiling  aeroplane standing little boy running and gentle man throwing displaying on screen\n",
      "..................................................\n",
      "Current validation loss: 3.483297348022461 \n",
      "\n",
      "Iteration 30000 \n",
      "\n",
      "Current train loss: 3.2912683486938477 \n",
      "1 a person is a baby of\n",
      "..................................................\n",
      "2 a man is a hand is a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man displays a graphic t-shirt that he made\n",
      "..................................................\n",
      "2 <BOS> a camera in his hand fixing lens inside and showing buttons displaying on the screen\n",
      "..................................................\n",
      "Current validation loss: 3.9633219242095947 \n",
      "Saved 30000\n",
      "\n",
      "Iteration 31000 \n",
      "\n",
      "Current train loss: 2.7064554691314697 \n",
      "1 two man is talking about something\n",
      "..................................................\n",
      "2 a man is a computer\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a person is talking about dust mites\n",
      "..................................................\n",
      "2 <BOS> a man analyzes a laptop\n",
      "..................................................\n",
      "Current validation loss: 3.427898645401001 \n",
      "\n",
      "Iteration 32000 \n",
      "\n",
      "Current train loss: 3.5172641277313232 \n",
      "1 a is a a man driving driving on fast\n",
      "..................................................\n",
      "2 a murray is being interviewed\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> there is  a vehicle is going very fast through the race road\n",
      "..................................................\n",
      "2 <BOS> bill murry is being interviewed by david letterman\n",
      "..................................................\n",
      "Current validation loss: 3.770721912384033 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 32000\n",
      "\n",
      "Iteration 33000 \n",
      "\n",
      "Current train loss: 3.666600227355957 \n",
      "1 a cartoon character is to a\n",
      "..................................................\n",
      "2 a of to and a background and\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a cartoon character speaks to people\n",
      "..................................................\n",
      "2 <BOS> numbers go up in the right corner\n",
      "..................................................\n",
      "Current validation loss: 3.9967732429504395 \n",
      "\n",
      "Iteration 34000 \n",
      "\n",
      "Current train loss: 3.3666536808013916 \n",
      "1 a man is a hat shirt is a man of a\n",
      "..................................................\n",
      "2 a man of on stage stage show\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man in a black tshirt shows a clip of halle sallasee running a race in slow motion\n",
      "..................................................\n",
      "2 <BOS> a couple dances on a tv show\n",
      "..................................................\n",
      "Current validation loss: 3.937234401702881 \n",
      "Saved 34000\n",
      "\n",
      "Iteration 35000 \n",
      "\n",
      "Current train loss: 3.477579116821289 \n",
      "1 a is talking a game and and and\n",
      "..................................................\n",
      "2 a is in the sky of of\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> someone is playing a game\n",
      "..................................................\n",
      "2 <BOS> technology institution on the show\n",
      "..................................................\n",
      "Current validation loss: 3.897437572479248 \n",
      "\n",
      "Iteration 36000 \n",
      "\n",
      "Current train loss: 3.215430736541748 \n",
      "1 a woman is cooking how to cook a\n",
      "..................................................\n",
      "2 a playing how to play a video\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a woman is showing how to make soup\n",
      "..................................................\n",
      "2 <BOS> man teaching how to light a fire\n",
      "..................................................\n",
      "Current validation loss: 3.704580307006836 \n",
      "Saved 36000\n",
      "\n",
      "Iteration 37000 \n",
      "\n",
      "Current train loss: 3.3267478942871094 \n",
      "1 a woman is a car\n",
      "..................................................\n",
      "2 a woman woman and in and a camera and a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man drive a car\n",
      "..................................................\n",
      "2 <BOS> a young man stands surprised at the words of woman stands in front of him\n",
      "..................................................\n",
      "Current validation loss: 3.9167301654815674 \n",
      "\n",
      "Iteration 38000 \n",
      "\n",
      "Current train loss: 3.4102118015289307 \n",
      "1 a young is playing a book\n",
      "..................................................\n",
      "2 a man player is a ball\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a girl is reading a book with other two girl s\n",
      "..................................................\n",
      "2 <BOS> a baseball player hits a ball and it is out at first base\n",
      "..................................................\n",
      "Current validation loss: 3.993659496307373 \n",
      "Saved 38000\n",
      "\n",
      "Iteration 39000 \n",
      "\n",
      "Current train loss: 3.2225680351257324 \n",
      "1 a game a of a game\n",
      "..................................................\n",
      "2 a a sea the sea are the the surfing the waves and\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> video showing gameplay from the game minecraft\n",
      "..................................................\n",
      "2 <BOS> in the sea the men mick fanning is attack the blue whale in adventurly\n",
      "..................................................\n",
      "Current validation loss: 3.886387348175049 \n",
      "\n",
      "Iteration 40000 \n",
      "\n",
      "Current train loss: 3.3312220573425293 \n",
      "1 a man is showing a piece piece piece\n",
      "..................................................\n",
      "2 a of a band of on on on on on\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a person is unpacking a large black box\n",
      "..................................................\n",
      "2 <BOS> video of a group sining\n",
      "..................................................\n",
      "Current validation loss: 4.279943466186523 \n",
      "Saved 40000\n",
      "\n",
      "Iteration 41000 \n",
      "\n",
      "Current train loss: 3.7574379444122314 \n",
      "1 a baby is lying in a floor and\n",
      "..................................................\n",
      "2 a man is talking a opinion\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a child is sleeping on the sofa\n",
      "..................................................\n",
      "2 <BOS> a man is giving his opinion on a television program\n",
      "..................................................\n",
      "Current validation loss: 3.73103928565979 \n",
      "\n",
      "Iteration 42000 \n",
      "\n",
      "Current train loss: 3.585073471069336 \n",
      "1 a animated truck a animated truck driving on truck of the orange\n",
      "..................................................\n",
      "2 a a video minecraft man is walking a man\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> 3d carttoon where an proclain is putting the boulders in an truck\n",
      "..................................................\n",
      "2 <BOS> in a cartoon a robot is helping a man\n",
      "..................................................\n",
      "Current validation loss: 3.5249178409576416 \n",
      "Saved 42000\n",
      "\n",
      "Iteration 43000 \n",
      "\n",
      "Current train loss: 3.311338424682617 \n",
      "1 a are and song\n",
      "..................................................\n",
      "2 a dog is being the cage\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> cartoons singing a song with the words on the page\n",
      "..................................................\n",
      "2 <BOS> cute kitten are in the bowl\n",
      "..................................................\n",
      "Current validation loss: 3.7732996940612793 \n",
      "\n",
      "Iteration 44000 \n",
      "\n",
      "Current train loss: 2.912651300430298 \n",
      "1 a men are running on on running the race\n",
      "..................................................\n",
      "2 a women are about a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> the players are running fast and wanting the first place\n",
      "..................................................\n",
      "2 <BOS> three women talking about politics\n",
      "..................................................\n",
      "Current validation loss: 3.5441198348999023 \n",
      "Saved 44000\n",
      "\n",
      "Iteration 45000 \n",
      "\n",
      "Current train loss: 3.5045769214630127 \n",
      "1 a man is playing something video\n",
      "..................................................\n",
      "2 a football player is\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man is explaining his work in a video game\n",
      "..................................................\n",
      "2 <BOS> a football game clip\n",
      "..................................................\n",
      "Current validation loss: 3.946031093597412 \n",
      "\n",
      "Iteration 46000 \n",
      "\n",
      "Current train loss: 3.572810173034668 \n",
      "1 a individual chef is on a recipe recipe\n",
      "..................................................\n",
      "2 a is her on\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> an inhome chef works on a chicken dish by describing the chicken she will be using\n",
      "..................................................\n",
      "2 <BOS> woman applying self tanner\n",
      "..................................................\n",
      "Current validation loss: 3.4368271827697754 \n",
      "Saved 46000\n",
      "\n",
      "Iteration 47000 \n",
      "\n",
      "Current train loss: 3.595473527908325 \n",
      "1 a is a man man man talking talking about front room\n",
      "..................................................\n",
      "2 a man is talking a phone\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> there is a black tshirt man is talking in a program\n",
      "..................................................\n",
      "2 <BOS> a man is showing the foot well under the door jam area of the car\n",
      "..................................................\n",
      "Current validation loss: 3.7646210193634033 \n",
      "\n",
      "Iteration 48000 \n",
      "\n",
      "Current train loss: 3.56229567527771 \n",
      "1 a food is in a man of a man chicken\n",
      "..................................................\n",
      "2 a man is playing a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> symphonic music plays as a picture of a toasted bagel with gold leaves on the cream cheese is shown\n",
      "..................................................\n",
      "2 <BOS> a man is playing minecraft\n",
      "..................................................\n",
      "Current validation loss: 3.4279332160949707 \n",
      "Saved 48000\n",
      "\n",
      "Iteration 49000 \n",
      "\n",
      "Current train loss: 3.2253761291503906 \n",
      "1 a man is a news show\n",
      "..................................................\n",
      "2 a man is showing a piece\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man discusses the tv show  the office \n",
      "..................................................\n",
      "2 <BOS> a man is holding a battery and a magnet and puts them together at the negative side\n",
      "..................................................\n",
      "Current validation loss: 3.696868419647217 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 50000 \n",
      "\n",
      "Current train loss: 3.4279513359069824 \n",
      "1 two men playing playing a ping of ping tennis\n",
      "..................................................\n",
      "2 a man is playing a the online video game game\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> two player teams play a game of table tennis against one another\n",
      "..................................................\n",
      "2 <BOS> a person is playing on an xbox one video game console\n",
      "..................................................\n",
      "Current validation loss: 3.692199468612671 \n",
      "Saved 50000\n",
      "\n",
      "Iteration 51000 \n",
      "\n",
      "Current train loss: 3.653903007507324 \n",
      "1 a players are running a scoring a goal\n",
      "..................................................\n",
      "2 a woman is in a\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> soccer team is playing and makes a goal everyone cheers\n",
      "..................................................\n",
      "2 <BOS> a doll dressed in bridal weal holding a goat in hand\n",
      "..................................................\n",
      "Current validation loss: 4.115060329437256 \n",
      "\n",
      "Iteration 52000 \n",
      "\n",
      "Current train loss: 3.3677501678466797 \n",
      "1 a man is up potato in a pieces\n",
      "..................................................\n",
      "2 a are being a food\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a man slices some potatoes into smaller pieces\n",
      "..................................................\n",
      "2 <BOS> doctors are discussing various issues\n",
      "..................................................\n",
      "Current validation loss: 3.7464993000030518 \n",
      "Saved 52000\n",
      "\n",
      "Iteration 53000 \n",
      "\n",
      "Current train loss: 3.5992932319641113 \n",
      "1 a are walking a street\n",
      "..................................................\n",
      "2 a band of on\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> people are on the roof and flying through the air\n",
      "..................................................\n",
      "2 <BOS> rock group dancing party\n",
      "..................................................\n",
      "Current validation loss: 3.301976203918457 \n",
      "\n",
      "Iteration 54000 \n",
      "\n",
      "Current train loss: 3.5749876499176025 \n",
      "1 a is a man man is talking to a man man\n",
      "..................................................\n",
      "2 a a and running a a large of a camera\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> there is a suit man is talking to a old man\n",
      "..................................................\n",
      "2 <BOS>  white male trots to a stairway to the cheers of a crowd and he removes a light t shirt exposing an undershirt typically worn by amateur\n",
      "..................................................\n",
      "Current validation loss: 4.020068168640137 \n",
      "Saved 54000\n",
      "\n",
      "Iteration 55000 \n",
      "\n",
      "Current train loss: 3.7097091674804688 \n",
      "1 a people are about a tv\n",
      "..................................................\n",
      "2 a one are in floor\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> three women talk around a table\n",
      "..................................................\n",
      "2 <BOS> some kittens explore the yard as the mother cat looks on\n",
      "..................................................\n",
      "Current validation loss: 3.421795606613159 \n",
      "\n",
      "Iteration 56000 \n",
      "\n",
      "Current train loss: 3.5284245014190674 \n",
      "1 a are a judges on a\n",
      "..................................................\n",
      "2 a is showing how to use a computer\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> judges review female singing and guitar playing\n",
      "..................................................\n",
      "2 <BOS> someone is showing how to use a thermostat\n",
      "..................................................\n",
      "Current validation loss: 3.7898552417755127 \n",
      "Saved 56000\n",
      "\n",
      "Iteration 57000 \n",
      "\n",
      "Current train loss: 3.8265812397003174 \n",
      "1 a woman is about front interview\n",
      "..................................................\n",
      "2 a man is talking a interview\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a woman talking in an interview\n",
      "..................................................\n",
      "2 <BOS> a man is doing an experiment with a candle\n",
      "..................................................\n",
      "Current validation loss: 3.1135733127593994 \n",
      "\n",
      "Iteration 58000 \n",
      "\n",
      "Current train loss: 3.224534511566162 \n",
      "1 a talking woman talking on\n",
      "..................................................\n",
      "2 two woman of people from a are a the scenes\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> guy and girl walking dog\n",
      "..................................................\n",
      "2 <BOS> a series of clips from movies showing off various guns\n",
      "..................................................\n",
      "Current validation loss: 4.350874423980713 \n",
      "Saved 58000\n",
      "\n",
      "Iteration 59000 \n",
      "\n",
      "Current train loss: 3.311300039291382 \n",
      "1 a man man in a electronic device of a computer\n",
      "..................................................\n",
      "2 a woman of of a in black dress black dress\n",
      "..................................................\n",
      "GT Captions\n",
      "1 <BOS> a young man holding an electronic peice on his arm and playing with some software\n",
      "..................................................\n",
      "2 <BOS> a still image of girl with glass in her hand showing scene\n",
      "..................................................\n",
      "Current validation loss: 3.635988235473633 \n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network config: \n",
      "N_Steps: 30\n",
      "Hidden_dim:500\n",
      "Frame_dim:2048\n",
      "Batch_size:1\n",
      "Vocab_size:29325\n",
      "\n",
      "Created weights\n",
      "Video_input: (1, 59, 500)\n",
      "Video_output: (1, 59, 500)\n",
      "Caption_input: (1, 59, 1000)\n",
      "Caption_output: (1, 59, 500)\n",
      "INFO:tensorflow:Restoring parameters from ./ckpt_v5/model_58000.ckpt\n",
      "Restored model\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a person\n",
      "..................................................\n",
      "1 <BOS> a person is\n",
      "..................................................\n",
      "1 <BOS> a person is cooking\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a dish\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a dish in\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a dish in a\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a dish in a pot\n",
      "..................................................\n",
      "1 <BOS> a person is cooking a dish in a pot\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> a woman shows a mixing technique\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a woman\n",
      "..................................................\n",
      "1 <BOS> a woman is\n",
      "..................................................\n",
      "1 <BOS> a woman is talking\n",
      "..................................................\n",
      "1 <BOS> a woman is talking about\n",
      "..................................................\n",
      "1 <BOS> a woman is talking about her\n",
      "..................................................\n",
      "1 <BOS> a woman is talking about her hair\n",
      "..................................................\n",
      "1 <BOS> a woman is talking about her hair\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> the food is placed in the plate while the woman on white sofa is talking\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a man\n",
      "..................................................\n",
      "1 <BOS> a man is\n",
      "..................................................\n",
      "1 <BOS> a man is talking\n",
      "..................................................\n",
      "1 <BOS> a man is talking about\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a video\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a video game\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a video game\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> a diglett fights a voltorb in an epic pokemon battle\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a man\n",
      "..................................................\n",
      "1 <BOS> a man and\n",
      "..................................................\n",
      "1 <BOS> a man and a\n",
      "..................................................\n",
      "1 <BOS> a man and a woman\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are walking\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are walking in\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are walking in a\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are walking in a park\n",
      "..................................................\n",
      "1 <BOS> a man and a woman are walking in a park\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> a group of children are playing in the forest while a man sings\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a man\n",
      "..................................................\n",
      "1 <BOS> a man is\n",
      "..................................................\n",
      "1 <BOS> a man is talking\n",
      "..................................................\n",
      "1 <BOS> a man is talking about\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a dog\n",
      "..................................................\n",
      "1 <BOS> a man is talking about a dog\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> a large spider is crawling on a white wall\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a man\n",
      "..................................................\n",
      "1 <BOS> a man is\n",
      "..................................................\n",
      "1 <BOS> a man is talking\n",
      "..................................................\n",
      "1 <BOS> a man is talking to\n",
      "..................................................\n",
      "1 <BOS> a man is talking to a\n",
      "..................................................\n",
      "1 <BOS> a man is talking to a woman\n",
      "..................................................\n",
      "1 <BOS> a man is talking to a woman\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> youtubers react to shia labouf the musical\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? y\n",
      "1 <BOS> a\n",
      "..................................................\n",
      "1 <BOS> a woman\n",
      "..................................................\n",
      "1 <BOS> a woman is\n",
      "..................................................\n",
      "1 <BOS> a woman is singing\n",
      "..................................................\n",
      "1 <BOS> a woman is singing\n",
      "..................................................\n",
      "............................\n",
      "GT Caption:\n",
      "\n",
      "1 <BOS> an older man sheds tears of joy while a young woman sings a song to a large audience\n",
      "..................................................\n",
      "Should I play the video? n\n",
      "Want another test run? n\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    with tf.Graph().as_default():\n",
    "        learning_rate = 0.00001\n",
    "        video,caption,caption_mask,output_logits,loss,dropout_prob = build_model()\n",
    "        optim = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "        ckpt_file = './ckpt_v5/model_58000.ckpt.meta'\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            if ckpt_file:\n",
    "                saver_ = tf.train.import_meta_graph(ckpt_file)\n",
    "                saver_.restore(sess,'./ckpt_v5/model_58000.ckpt')\n",
    "                print (\"Restored model\")\n",
    "            else:\n",
    "                sess.run(tf.initialize_all_variables())\n",
    "            while(1):\n",
    "                vid,caption_GT,_,current_batch_vids = fetch_data_batch_val(1)\n",
    "                caps,caps_mask = convert_caption(['<BOS>'],word2id,30)\n",
    "\n",
    "                for i in range(30):\n",
    "                    o_l = sess.run(output_logits,feed_dict={video:vid,\n",
    "                                                            caption:caps,\n",
    "                                                            caption_mask:caps_mask,\n",
    "                                                            dropout_prob:1.0})\n",
    "                    out_logits = o_l.reshape([batch_size,n_steps-1,vocab_size])\n",
    "                    output_captions = np.argmax(out_logits,2)\n",
    "                    caps[0][i+1] = output_captions[0][i]\n",
    "                    print_in_english(caps)\n",
    "                    if id2word[output_captions[0][i]] == '<EOS>':\n",
    "                        break\n",
    "                print ('............................\\nGT Caption:\\n')\n",
    "                print_in_english(caption_GT)\n",
    "                play_video = input('Should I play the video? ')\n",
    "                if play_video.lower() == 'y':\n",
    "                    playVideo(current_batch_vids)\n",
    "                test_again = input('Want another test run? ')\n",
    "                if test_again.lower() == 'n':\n",
    "                    break\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, GRU, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from Attention import Attention_Layer\n",
    "from Multimodel_layer import Multimodel_Layer\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "class Caption_Generator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.captions = []\n",
    "        self.captions_in_each_video = []\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.max_sentence_length = 0\n",
    "        self.vocabulary_size = 0\n",
    "        self.batch_size = 25\n",
    "        self.embedding_output_shape = 512\n",
    "        \n",
    "    ################################################################################################\n",
    "    def read_data(self, n_batch):\n",
    "        print \"loading Data for new Batch... \"\n",
    "        files = [] \n",
    "    \n",
    "        #reading captions\n",
    "        with open('MLDS_HW2/MLDS_hw2_data/training_label.json') as data_file:\n",
    "            training_labels = json.load(data_file)\n",
    "        \n",
    "        \n",
    "        self.captions_in_each_video = []\n",
    "        for i in n_batch:\n",
    "            files.append(training_labels[i]['id'])\n",
    "            for j in range(len(training_labels[i]['caption'])):\n",
    "                training_labels[i]['caption'][j] = \"<s> \"+training_labels[i]['caption'][j]+\" <e>\" \n",
    "                self.captions.append(training_labels[i]['caption'][j].lower().split(' '))\n",
    "            self.captions_in_each_video.append(len(training_labels[i]['caption']))\n",
    "\n",
    "        \n",
    "        #reading video features\n",
    "        video_features = np.zeros((len(files),80,4096))\n",
    "        \n",
    "        video_features[0] = np.load(\"MLDS_HW2/MLDS_hw2_data/training_data/feat/\"+files[0]+\".npy\")\n",
    "\n",
    "        for i in range(1,len(files)):\n",
    "            video_features[i] = np.load(\"MLDS_HW2/MLDS_hw2_data/training_data/feat/\"+files[i]+\".npy\")\n",
    "        \n",
    "        print \"Data Loaded Successfully.....\"\n",
    "\n",
    "        return video_features\n",
    "    ################################################################################################\n",
    "    def create_vocabulary(self):\n",
    "\n",
    "        print \"creating vocabulary...\"\n",
    "        labels = []\n",
    "        with open('MLDS_HW2/MLDS_hw2_data/training_label.json') as data_file:\n",
    "            training_labels = json.load(data_file)\n",
    "        \n",
    "        for i in range(len(training_labels)):\n",
    "            for j in range(len(training_labels[i]['caption'])):\n",
    "                training_labels[i]['caption'][j] = \"<s> \"+training_labels[i]['caption'][j]+\" <e>\" \n",
    "                labels.append(training_labels[i]['caption'][j].lower().split(' '))\n",
    "        \n",
    "        self.max_sentence_length = 1 + max([len(caption) for caption in labels])\n",
    "        print(\"\\t Max sentence length : \", self.max_sentence_length)\n",
    "         \n",
    "        #computing char2id and id2char vocabulary\n",
    "        index = 0\n",
    "        for caption in labels:\n",
    "            for word in caption:\n",
    "                if word not in self.word2id:\n",
    "                    self.word2id[word] = index\n",
    "                    self.id2word[index] = word\n",
    "                    index += 1\n",
    "                    \n",
    "        \n",
    "        self.vocabulary_size = len(self.word2id)\n",
    "    \n",
    "       \n",
    "            \n",
    "    ################################################################################################\n",
    "    def transform_inputs(self, video_features):\n",
    "        #transforming the no of samples of video features equal to no of samples of captions\n",
    "        new_features = np.zeros((len(self.captions), 80, 4096))\n",
    "        for i in range(len(self.captions_in_each_video)):\n",
    "            for j in range(self.captions_in_each_video[i]):\n",
    "                new_features[j] = video_features[i]\n",
    "                \n",
    "        return new_features\n",
    "            \n",
    "    \n",
    "    ################################################################################################\n",
    "    def one_of_N_encoding(self): \n",
    "        print(\"encoding inputs...\")      \n",
    "        #creating caption tensor that is a matrix of size numCaptions x maximumSentenceLength x wordVocabularySize\n",
    "        encoded_tensor = np.zeros((len(self.captions), self.max_sentence_length, self.vocabulary_size), dtype=np.float16)\n",
    "        label_tensor = np.zeros((len(self.captions), self.max_sentence_length, self.vocabulary_size), dtype =np.float16)\n",
    "        #one-hot-encoding\n",
    "        for i in range(len(self.captions)):\n",
    "            for j in range(len(self.captions[i])):\n",
    "                encoded_tensor[i, j, self.word2id[self.captions[i][j]]] = 1\n",
    "                if j<len(self.captions[i])-1:\n",
    "                    label_tensor[i,j,self.word2id[self.captions[i][j+1]]] = 1\n",
    "                \n",
    "        return encoded_tensor, label_tensor\n",
    "    \n",
    "    ################################################################################################\n",
    "    def embedding_layer(self, input_data):\n",
    "        print(\"embedding inputs....\")\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.embedding_output_shape, input_shape = (self.max_sentence_length, self.vocabulary_size)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.compile('rmsprop','mse')\n",
    "        embedding_weights = model.get_weights()\n",
    "        output_array = model.predict(input_data)\n",
    "        self.embedding_weights = model.get_weights()\n",
    "        output_weights = np.asarray(self.embedding_weights[0]).T\n",
    "        self.embedding_weights[0] = output_weights\n",
    "        self.embedding_weights[1] = np.ones((self.vocabulary_size,))\n",
    "        return output_array\n",
    "    \n",
    "    ################################################################################################\n",
    "    def data_preprocessing(self, n_batch):\n",
    "        #########################Preprocessing Data##############################\n",
    "        #print(\"Data Preprocessing.......\")\n",
    "        #print(\"\\tReading data.......\")\n",
    "        video_features = self.read_data(n_batch)\n",
    "        video_features = self.transform_inputs(video_features)\n",
    "        #print(\"\\tvideo features : \",video_features.shape)\n",
    "        #print(\"\\tCaptions : \", len(self.captions))\n",
    "        #print(\"\\tCreating Vocabulary......\")\n",
    "        #self.create_vocabulary()\n",
    "\n",
    "        # one-hot encoding of captions\n",
    "        #print(\"\\tEncoding Captions......\")\n",
    "        encoded_tensor, label_tensor = self.one_of_N_encoding()\n",
    "        #print(\"\\tEncoded Captions : \",encoded_tensor.shape)\n",
    "\n",
    "        # embedding the one-hot encoding of each word into 512\n",
    "        #print(\"\\tEmbedding Captions.......\")\n",
    "        embedded_input = self.embedding_layer(encoded_tensor)\n",
    "\n",
    "        #print(\"\\tEmbedding Weights : \", np.asarray(self.embedding_weights[0]).shape)\n",
    "\n",
    "        #print(\"\\tEmbedded_captions : \",embedded_input.shape)\n",
    "        \n",
    "        return video_features, embedded_input, label_tensor\n",
    "        \n",
    "    ################################################################################################    \n",
    "    def build_model(self, video_features, embedded_input):\n",
    "        #########################training model##################################\n",
    "        print('Building Sentence Generator Model...')\n",
    "\n",
    "        input1 = Input(shape=(embedded_input.shape[1],embedded_input.shape[2]), dtype='float32')\n",
    "        #input2 = Input(shape=(visual_features.shape[0],visual_features.shape[1]), dtype='float32')\n",
    "        input2 = Input(shape=(video_features.shape[1], video_features.shape[2]), dtype='float32')\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        layer1 = GRU(512, return_sequences = True, input_shape = (embedded_input.shape[1],embedded_input.shape[2]), activation = 'relu')(input1)\n",
    "        \n",
    "        attention_layer = Attention_Layer(output_dim = 32)([layer1, input2])\n",
    "\n",
    "        multimodel_layer = Multimodel_Layer(output_dim = 1024)([layer1,attention_layer])\n",
    "\n",
    "        dropout = Dropout(0.5)(multimodel_layer)\n",
    "\n",
    "        layer2 = TimeDistributed(Dense(activation = 'tanh', units = 512))(dropout)\n",
    "\n",
    "        softmax_layer = Dense(units = self.vocabulary_size, activation = 'softmax', weights = self.embedding_weights)(layer2)\n",
    "        \n",
    "        model = Model(inputs = [input1, input2], outputs = [softmax_layer])\n",
    "        \n",
    "        '''\n",
    "        # We also specify here the optimization we will use, in this case we use RMSprop with learning rate 0.001.\n",
    "        # RMSprop is commonly used for RNNs instead of regular SGD.\n",
    "        # categorical_crossentropy is the same loss used for classification problems using softmax. (nn.ClassNLLCriterion)\n",
    "        '''\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr=0.001))\n",
    "\n",
    "        print(model.summary()) # Convenient function to see details about the network model.\n",
    "\n",
    "        return model\n",
    "    \n",
    "    ################################################################################################    \n",
    "    def train(self):       \n",
    "        \n",
    "        batches = np.arange(1450)\n",
    "        #########################training model##################################\n",
    "        for epoch in range(10):\n",
    "            print \"\\n\\n\\nEpoch : \",epoch+1\n",
    "            np.random.shuffle(batches)\n",
    "            batch = 0\n",
    "            for iteration in range(1450/self.batch_size):\n",
    "                if batch+self.batch_size >= 1450:\n",
    "                    n_batch = batches[batch:-1]\n",
    "                else:    \n",
    "                    n_batch = batches[batch:(batch+self.batch_size)]\n",
    "                batch += self.batch_size\n",
    "                self.captions = []\n",
    "                video_features, embedded_input, label_tensor = self.data_preprocessing(n_batch)\n",
    "                if(iteration == 0 and epoch == 0):\n",
    "                    model = caption_generator.build_model(video_features, embedded_input)\n",
    "                # define the checkpoint\n",
    "                filepath=\"Sentence_Generator_Model_Results/word-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "                checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "                callbacks_list = [checkpoint]\n",
    "\n",
    "                print\"\\n\\n###########Training the model on epoch : \", epoch+1, \" batch : \", iteration+1 ,\" ###########\\n\\n\"\n",
    "                model.fit(x = [embedded_input,video_features], y = label_tensor, batch_size = 256, epochs= 5, callbacks = callbacks_list)\n",
    "            self.save_model(model,epoch)\n",
    "            \n",
    "            \n",
    "        return model\n",
    "    \n",
    "    ################################################################################################    \n",
    "    def save_model(self, model, epoch):\n",
    "        # serialize model to JSON\n",
    "        filename = \"Sentence_Generator_Model_Results/model_epoch_\"+str(epoch)+\".h5\"\n",
    "        #with open(\"batch_model.json\", \"w\") as json_file:\n",
    "            #json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(filename)\n",
    "        print(\"Saved model to disk\")\n",
    "        \n",
    "    ################################################################################################    \n",
    "    def load_model(self, model, epoch):\n",
    "        # load weights into new model\n",
    "        filename = \"Sentence_Generator_Model_Results/model_epoch_\"+str(epoch)+\".h5\"\n",
    "        model.load_weights(filename)\n",
    "        print(\"Loaded model from disk\")\n",
    "        return model\n",
    "    \n",
    "    ################################################################################################    \n",
    "    def test(self, model, epoch):\n",
    "\n",
    "        print(\"word : \",self.id2word[0])\n",
    "        test_captions = []\n",
    "        with open('MLDS_HW2/MLDS_hw2_data/testing_public_label.json') as data_file:\n",
    "            testing_labels = json.load(data_file)\n",
    "        \n",
    "        files = []\n",
    "        self.captions_in_each_video = []\n",
    "\n",
    "        for i in range(len(testing_labels)):\n",
    "            files.append(testing_labels[i]['id'])\n",
    "            for j in range(len(testing_labels[i]['caption'])):\n",
    "                test_captions.append(testing_labels[i]['caption'][j].lower().split(' '))\n",
    "            self.captions_in_each_video.append(j)\n",
    "        \n",
    "        encoded_tensor = np.zeros((len(test_captions), self.max_sentence_length, self.vocabulary_size), dtype=np.float16)\n",
    "        encoded_tensor[:,0,0] = 1\n",
    "\n",
    "        print(\"number of files : \",len(files))\n",
    "        #reading video features\n",
    "        video_features = np.zeros((len(files),80,4096))\n",
    "        \n",
    "        print(\"shape : \",np.load(\"MLDS_HW2/MLDS_hw2_data/testing_data/feat/\"+files[0]+\".npy\").shape)\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            video_features[i] = np.load(\"MLDS_HW2/MLDS_hw2_data/testing_data/feat/\"+files[i]+\".npy\")\n",
    "\n",
    "        new_features = np.zeros((len(self.captions), 80, 4096))\n",
    "        for i in range(len(self.captions_in_each_video)):\n",
    "            for j in range(self.captions_in_each_video[i]):\n",
    "                new_features[j] = video_features[i]\n",
    "        \n",
    "        new_features = np.reshape(new_features, (len(self.captions)*80, 1, 4096))\n",
    "        \n",
    "\n",
    "        #print(\"new_features : \", new_features.shape)\n",
    "        encoded_tensor = np.repeat(encoded_tensor, 80, axis=0)\n",
    "\n",
    "        embedded_input = self.embedding_layer(encoded_tensor)\n",
    "\n",
    "        print(\"embedded_input : \", embedded_input.shape)\n",
    "        print(\"video_features : \", new_features.shape)\n",
    "\n",
    "        model  = self.build_model()\n",
    "        model = self.load_model(model)\n",
    "\n",
    "        output = model.predict([embedded_input[:200,:,:], new_features[:200,:,:]])\n",
    "        \n",
    "        with open(\"Model_Results/Results/generated_text_epoch\"+str(epoch)+\".txt\", \"a\") as fileHandler:\n",
    "            \n",
    "            for i in range(200):\n",
    "                text = \"\"\n",
    "                for j in range(41):\n",
    "                    word = np.argmax(output[i,j,:])\n",
    "                    text += self.id2word[word]\n",
    "                    text += \" \"\n",
    "                fileHandler.write(\"Generated text for example \",i,\" : \", text)\n",
    "                fileHandler.write(\"\\n\")\n",
    "            fileHandler.close()    \n",
    "            \n",
    "\n",
    "    ################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "caption_generator = Caption_Generator()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "caption_generator.create_vocabulary()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "model = caption_generator.train()\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 06:22:12 up  1:41,  4 users,  load average: 1.11, 0.35, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 193 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 192 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.4 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.3 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 99.0 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.3 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24606748 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   584804 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1560672 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25745880 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3645 narain.+  20   0  304328  56088  12332 S   6.7  0.2   0:01.78 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   15 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 ksoftirqd/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   19 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/2     \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 06:22:15 up  1:41,  4 users,  load average: 1.11, 0.35, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 193 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 192 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.4 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 99.0 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.4 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24606688 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   584772 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1560764 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25745940 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3741 narain.+  20   0  598636  47232  11280 S   1.3  0.2   0:00.82 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2519 root     -51   0       0      0      0 S   0.3  0.0   0:11.24 irq/37-nvi+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4348 narain.+  20   0   40520   3740   3132 R   0.3  0.0   0:00.01 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   15 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 ksoftirqd/1 \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 06:22:18 up  1:41,  4 users,  load average: 1.02, 0.35, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.4 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 99.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24606720 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   584744 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1560760 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25745964 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3741 narain.+  20   0  598636  47232  11280 S   2.0  0.2   0:00.88 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3028 root      20   0  304464  60808  12320 S   0.3  0.2   0:05.03 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   15 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 ksoftirqd/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:+ \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 06:22:21 up  1:41,  4 users,  load average: 0.94, 0.34, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.5 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.3 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 97.4 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  1.8 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24606148 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   583912 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1562164 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25746696 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3741 narain.+  20   0  598636  47232  11280 S   1.7  0.2   0:00.93 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3028 root      20   0  304464  60808  12320 S   1.3  0.2   0:05.07 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2519 root     -51   0       0      0      0 S   0.3  0.0   0:11.25 irq/37-nvi+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3220 srihars+  20   0   97824   5180   3756 S   0.3  0.0   0:00.32 sshd        \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 4348 narain.+  20   0   40520   3740   3132 R   0.3  0.0   0:00.02 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 06:22:24 up  1:41,  4 users,  load average: 0.94, 0.34, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.4 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 99.3 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24606180 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   583892 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1562152 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25746772 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3741 narain.+  20   0  598636  47232  11280 S   1.7  0.2   0:00.98 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   15 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 ksoftirqd/1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   19 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/2     \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 06:22:27 up  1:41,  4 users,  load average: 0.86, 0.34, 0.12\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  0.6 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  0.2 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 99.2 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 26752224 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 24605808 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m   584240 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m  1562176 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m        0 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 25746428 \u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3741 narain.+  20   0  598636  47232  11280 S   1.7  0.2   0:01.03 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   48 root      20   0       0      0      0 S   0.3  0.0   0:03.27 kworker/3:1 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 2519 root     -51   0       0      0      0 S   0.3  0.0   0:11.26 irq/37-nvi+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3645 narain.+  20   0  304328  56088  12332 S   0.3  0.2   0:01.79 jupyter-no+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  119952   6100   3976 S   0.0  0.0   0:07.39 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    6 root      20   0       0      0      0 S   0.0  0.0   0:00.02 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root      20   0       0      0      0 S   0.0  0.0   0:00.12 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 lru-add-dr+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 watchdog/1  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   15 root      rt   0       0      0      0 S   0.0  0.0   0:00.00 migration/1 \u001b[m\u001b[m\u001b[K\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
